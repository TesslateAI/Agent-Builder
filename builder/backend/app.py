# backend/app.py
# builder/backend/app.py
import os
import asyncio
import json
import logging
import time # For run_id

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from dotenv import load_dotenv

# TFrameX v1.1.0 core components
from tframex import (
    TFrameXApp, TFrameXRuntimeContext, Message, FlowContext,
    setup_logging, Flow
)

# Local TFrameX application setup and component management
from tframex_config import get_tframex_app_instance
from component_manager import discover_tframex_components, register_code_dynamically
from flow_translator import translate_visual_to_tframex_flow
from database import (
    create_project, get_project, list_projects,
    save_flow, get_flow, list_flows, delete_flow,
    create_flow_execution, update_flow_execution, get_flow_executions
)

# Model configuration storage (in-memory for now, can be moved to database later)
MODEL_CONFIGS = {
    'default': {
        'id': 'default',
        'name': 'Default Model',
        'provider': 'openai',
        'model_name': os.getenv("OPENAI_MODEL_NAME") or os.getenv("LLAMA_MODEL") or "gpt-3.5-turbo",
        'api_key': os.getenv("OPENAI_API_KEY") or os.getenv("LLAMA_API_KEY") or "ollama",
        'base_url': os.getenv("OPENAI_API_BASE") or os.getenv("LLAMA_BASE_URL") or "http://localhost:11434/v1",
        'is_default': True
    }
}

load_dotenv()
# Use TFrameX's setup_logging for consistency
setup_logging(level=logging.INFO, use_colors=True)
logger = logging.getLogger("FlaskTFrameXStudio")

app = Flask(__name__, static_folder='../frontend/dist', static_url_path='')
# Configure CORS for development and production
CORS(app, resources={
    r"/api/*": {
        "origins": [
            "http://localhost:5173",  # Vite dev server
            "http://127.0.0.1:5173",
            "http://localhost:5000",  # Production
            "http://127.0.0.1:5000"
        ]
    }
})

TFRAMEX_GENERATED_FILES_DIR = "tframex_generated_outputs" # Directory for files generated by TFrameX flows/tools
os.makedirs(TFRAMEX_GENERATED_FILES_DIR, exist_ok=True)

# Initialize TFrameX App on startup
global_tframex_app = get_tframex_app_instance() # Renamed for clarity

# --- API Endpoints ---

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint for Docker"""
    return jsonify({"status": "healthy", "timestamp": time.time()}), 200

@app.route('/')
def index():
    """Serve the frontend in production, or API status in development"""
    frontend_dist = os.path.join(os.path.dirname(__file__), '../frontend/dist/index.html')
    if os.path.exists(frontend_dist):
        return send_from_directory('../frontend/dist', 'index.html')
    return jsonify({
        "status": "running",
        "message": "TFrameX Agent-Builder Backend API",
        "version": "1.0.0",
        "tframex_version": "1.1.0",
        "endpoints": [
            "/api/tframex/components",
            "/api/tframex/mcp/status",
            "/api/tframex/register_code",
            "/api/tframex/flow/execute",
            "/api/tframex/chatbot_flow_builder"
        ]
    })

@app.route('/<path:path>')
def serve_static(path):
    """Serve static files in production"""
    if path.startswith('api/'):
        return jsonify({"error": "Not found"}), 404
    frontend_dist = os.path.join(os.path.dirname(__file__), '../frontend/dist')
    if os.path.exists(os.path.join(frontend_dist, path)):
        return send_from_directory('../frontend/dist', path)
    # For SPA routing, return index.html for non-existent paths
    return send_from_directory('../frontend/dist', 'index.html')

@app.route('/api/tframex/components', methods=['GET'])
def list_tframex_studio_components():
    logger.info("Request received for /api/tframex/components")
    try:
        # Components are discovered from the global app instance
        components = discover_tframex_components(app_instance=global_tframex_app)
        return jsonify(components)
    except Exception as e:
        logger.error(f"Error discovering TFrameX components: {e}", exc_info=True)
        return jsonify({"error": "Failed to load TFrameX components from backend"}), 500

# --- Flow Persistence API ---

@app.route('/api/tframex/projects', methods=['GET', 'POST'])
def handle_projects():
    """List projects or create a new one"""
    if request.method == 'GET':
        projects = list_projects()
        return jsonify(projects)
    
    elif request.method == 'POST':
        data = request.get_json()
        project_id = data.get('id', f"project_{int(time.time())}")
        name = data.get('name', 'Untitled Project')
        description = data.get('description', '')
        
        try:
            # Ensure default project exists
            if project_id == 'default_project' and not get_project('default_project'):
                create_project('default_project', 'Default Project', 'Default workspace')
            else:
                project = create_project(project_id, name, description)
            return jsonify(project), 201
        except Exception as e:
            logger.error(f"Error creating project: {e}")
            return jsonify({"error": str(e)}), 500

@app.route('/api/tframex/flows', methods=['GET', 'POST'])
def handle_flows():
    """List flows or save a new/updated flow"""
    if request.method == 'GET':
        project_id = request.args.get('project_id')
        flows = list_flows(project_id)
        return jsonify(flows)
    
    elif request.method == 'POST':
        data = request.get_json()
        flow_id = data.get('id', f"flow_{int(time.time())}")
        project_id = data.get('project_id', 'default_project')
        
        # Ensure project exists
        if not get_project(project_id):
            create_project(project_id, 'Default Project', 'Auto-created project')
        
        try:
            flow = save_flow(
                flow_id=flow_id,
                project_id=project_id,
                name=data.get('name', 'Untitled Flow'),
                nodes=data.get('nodes', []),
                edges=data.get('edges', []),
                description=data.get('description', ''),
                metadata=data.get('metadata', {})
            )
            return jsonify(flow), 201
        except Exception as e:
            logger.error(f"Error saving flow: {e}")
            return jsonify({"error": str(e)}), 500

@app.route('/api/tframex/flows/<flow_id>', methods=['GET', 'DELETE'])
def handle_flow(flow_id):
    """Get or delete a specific flow"""
    if request.method == 'GET':
        flow = get_flow(flow_id)
        if flow:
            return jsonify(flow)
        return jsonify({"error": "Flow not found"}), 404
    
    elif request.method == 'DELETE':
        if delete_flow(flow_id):
            return jsonify({"message": "Flow deleted"}), 200
        return jsonify({"error": "Flow not found"}), 404

@app.route('/api/tframex/flows/<flow_id>/executions', methods=['GET'])
def get_flow_execution_history(flow_id):
    """Get execution history for a flow"""
    limit = request.args.get('limit', 10, type=int)
    executions = get_flow_executions(flow_id, limit)
    return jsonify(executions)

@app.route('/api/tframex/mcp/status', methods=['GET'])
def get_mcp_status():
    """Get the status of MCP integration (v1.1.0 feature)"""
    logger.info("Request received for /api/tframex/mcp/status")
    try:
        mcp_status = {
            "enabled": False,
            "servers": [],
            "meta_tools": []
        }
        
        if hasattr(global_tframex_app, '_mcp_manager') and global_tframex_app._mcp_manager:
            mcp_status["enabled"] = True
            
            # Get connected servers
            if hasattr(global_tframex_app._mcp_manager, '_connected_servers'):
                for server_alias in global_tframex_app._mcp_manager._connected_servers:
                    mcp_status["servers"].append({
                        "alias": server_alias,
                        "status": "connected"
                    })
            
            # List MCP meta-tools
            mcp_meta_tool_names = [
                "tframex_list_mcp_servers",
                "tframex_list_mcp_resources", 
                "tframex_read_mcp_resource",
                "tframex_list_mcp_prompts",
                "tframex_use_mcp_prompt"
            ]
            for tool_name in mcp_meta_tool_names:
                if tool_name in global_tframex_app._tools:
                    mcp_status["meta_tools"].append(tool_name)
        
        return jsonify(mcp_status)
    except Exception as e:
        logger.error(f"Error getting MCP status: {e}", exc_info=True)
        return jsonify({"error": "Failed to get MCP status"}), 500

# MCP Server Management Endpoints
@app.route('/api/tframex/mcp/servers/connect', methods=['POST'])
def connect_mcp_server():
    """Connect to an MCP server"""
    logger.info("Request received for /api/tframex/mcp/servers/connect")
    try:
        data = request.get_json()
        server_alias = data.get('server_alias')
        command = data.get('command')
        args = data.get('args', [])
        env = data.get('env', {})
        
        if not server_alias or not command:
            return jsonify({
                "success": False,
                "message": "Server alias and command are required"
            }), 400
        
        # Check if MCP manager is available
        if not hasattr(global_tframex_app, '_mcp_manager') or not global_tframex_app._mcp_manager:
            return jsonify({
                "success": False,
                "message": "MCP manager is not initialized"
            }), 500
        
        # Create server config
        server_config = {
            server_alias: {
                "command": command,
                "args": args,
                "env": env
            }
        }
        
        async def connect_server():
            try:
                # Initialize the server using MCP manager
                await global_tframex_app._mcp_manager.initialize_servers(server_config)
                
                # Get server info
                if server_alias in global_tframex_app._mcp_manager._connected_servers:
                    connected_server = global_tframex_app._mcp_manager._connected_servers[server_alias]
                    
                    # Extract available capabilities
                    tools = []
                    resources = []
                    prompts = []
                    
                    if hasattr(connected_server, 'tools') and connected_server.tools:
                        tools = [{"name": tool.name, "description": tool.description} 
                                for tool in connected_server.tools]
                    
                    if hasattr(connected_server, 'resources') and connected_server.resources:
                        resources = [{"name": resource.name} 
                                   for resource in connected_server.resources]
                    
                    if hasattr(connected_server, 'prompts') and connected_server.prompts:
                        prompts = [{"name": prompt.name} 
                                 for prompt in connected_server.prompts]
                    
                    return {
                        "success": True,
                        "message": f"Successfully connected to MCP server '{server_alias}'",
                        "server_info": {
                            "alias": server_alias,
                            "status": "connected",
                            "tools": tools,
                            "resources": resources,
                            "prompts": prompts
                        }
                    }
                else:
                    return {
                        "success": False,
                        "message": f"Failed to connect to MCP server '{server_alias}'"
                    }
                    
            except Exception as e:
                logger.error(f"Error connecting to MCP server '{server_alias}': {e}", exc_info=True)
                return {
                    "success": False,
                    "message": f"Connection failed: {str(e)}"
                }
        
        result = asyncio.run(connect_server())
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"Error in connect_mcp_server: {e}", exc_info=True)
        return jsonify({
            "success": False,
            "message": f"Server error: {str(e)}"
        }), 500

@app.route('/api/tframex/mcp/servers/disconnect', methods=['POST'])
def disconnect_mcp_server():
    """Disconnect from an MCP server"""
    logger.info("Request received for /api/tframex/mcp/servers/disconnect")
    try:
        data = request.get_json()
        server_alias = data.get('server_alias')
        
        if not server_alias:
            return jsonify({
                "success": False,
                "message": "Server alias is required"
            }), 400
        
        # Check if MCP manager is available
        if not hasattr(global_tframex_app, '_mcp_manager') or not global_tframex_app._mcp_manager:
            return jsonify({
                "success": False,
                "message": "MCP manager is not initialized"
            }), 500
        
        async def disconnect_server():
            try:
                # Check if server is connected
                if server_alias in global_tframex_app._mcp_manager._connected_servers:
                    connected_server = global_tframex_app._mcp_manager._connected_servers[server_alias]
                    
                    # Close the connection
                    if hasattr(connected_server, 'close'):
                        await connected_server.close()
                    
                    # Remove from connected servers
                    del global_tframex_app._mcp_manager._connected_servers[server_alias]
                    
                    return {
                        "success": True,
                        "message": f"Successfully disconnected from MCP server '{server_alias}'"
                    }
                else:
                    return {
                        "success": False,
                        "message": f"MCP server '{server_alias}' is not connected"
                    }
                    
            except Exception as e:
                logger.error(f"Error disconnecting from MCP server '{server_alias}': {e}", exc_info=True)
                return {
                    "success": False,
                    "message": f"Disconnection failed: {str(e)}"
                }
        
        result = asyncio.run(disconnect_server())
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"Error in disconnect_mcp_server: {e}", exc_info=True)
        return jsonify({
            "success": False,
            "message": f"Server error: {str(e)}"
        }), 500

@app.route('/api/tframex/mcp/servers/<server_alias>/status', methods=['GET'])
def get_mcp_server_status(server_alias):
    """Get the status of a specific MCP server"""
    logger.info(f"Request received for /api/tframex/mcp/servers/{server_alias}/status")
    try:
        # Check if MCP manager is available
        if not hasattr(global_tframex_app, '_mcp_manager') or not global_tframex_app._mcp_manager:
            return jsonify({
                "success": False,
                "message": "MCP manager is not initialized"
            }), 500
        
        # Check if server is connected
        if server_alias in global_tframex_app._mcp_manager._connected_servers:
            connected_server = global_tframex_app._mcp_manager._connected_servers[server_alias]
            
            # Extract current capabilities
            tools = []
            resources = []
            prompts = []
            
            if hasattr(connected_server, 'tools') and connected_server.tools:
                tools = [{"name": tool.name, "description": tool.description} 
                        for tool in connected_server.tools]
            
            if hasattr(connected_server, 'resources') and connected_server.resources:
                resources = [{"name": resource.name} 
                           for resource in connected_server.resources]
            
            if hasattr(connected_server, 'prompts') and connected_server.prompts:
                prompts = [{"name": prompt.name} 
                         for prompt in connected_server.prompts]
            
            return jsonify({
                "success": True,
                "server_info": {
                    "alias": server_alias,
                    "status": "connected",
                    "tools": tools,
                    "resources": resources,
                    "prompts": prompts
                }
            })
        else:
            return jsonify({
                "success": True,
                "server_info": {
                    "alias": server_alias,
                    "status": "disconnected",
                    "tools": [],
                    "resources": [],
                    "prompts": []
                }
            })
            
    except Exception as e:
        logger.error(f"Error getting MCP server status for '{server_alias}': {e}", exc_info=True)
        return jsonify({
            "success": False,
            "message": f"Server error: {str(e)}"
        }), 500

# Model Management Endpoints
@app.route('/api/tframex/models', methods=['GET'])
def get_models():
    """Get all configured models"""
    logger.info("Request received for /api/tframex/models")
    try:
        models = list(MODEL_CONFIGS.values())
        return jsonify({"models": models})
    except Exception as e:
        logger.error(f"Error getting models: {e}", exc_info=True)
        return jsonify({"error": "Failed to get models"}), 500

@app.route('/api/tframex/models', methods=['POST'])
def add_model():
    """Add a new model configuration"""
    logger.info("Request received to add model")
    try:
        data = request.json
        required_fields = ['name', 'provider', 'model_name', 'api_key', 'base_url']
        
        for field in required_fields:
            if field not in data:
                return jsonify({"error": f"Missing required field: {field}"}), 400
        
        # Generate unique ID
        model_id = f"model_{len(MODEL_CONFIGS)}_{int(time.time())}"
        
        # Create model config
        model_config = {
            'id': model_id,
            'name': data['name'],
            'provider': data['provider'],
            'model_name': data['model_name'],
            'api_key': data['api_key'],
            'base_url': data['base_url'],
            'is_default': False,
            'temperature': data.get('temperature', 0.7),
            'max_tokens': data.get('max_tokens', 2000)
        }
        
        MODEL_CONFIGS[model_id] = model_config
        logger.info(f"Added model configuration: {model_id}")
        
        return jsonify({"model": model_config}), 201
    except Exception as e:
        logger.error(f"Error adding model: {e}", exc_info=True)
        return jsonify({"error": "Failed to add model"}), 500

@app.route('/api/tframex/models/<model_id>', methods=['DELETE'])
def delete_model(model_id):
    """Delete a model configuration"""
    logger.info(f"Request received to delete model: {model_id}")
    try:
        if model_id not in MODEL_CONFIGS:
            return jsonify({"error": "Model not found"}), 404
        
        if MODEL_CONFIGS[model_id].get('is_default'):
            return jsonify({"error": "Cannot delete default model"}), 400
        
        del MODEL_CONFIGS[model_id]
        logger.info(f"Deleted model configuration: {model_id}")
        
        return jsonify({"message": "Model deleted successfully"}), 200
    except Exception as e:
        logger.error(f"Error deleting model: {e}", exc_info=True)
        return jsonify({"error": "Failed to delete model"}), 500

@app.route('/api/tframex/models/<model_id>/default', methods=['PUT'])
def set_default_model(model_id):
    """Set a model as default"""
    logger.info(f"Request received to set default model: {model_id}")
    try:
        if model_id not in MODEL_CONFIGS:
            return jsonify({"error": "Model not found"}), 404
        
        # Remove default from all models
        for mid, config in MODEL_CONFIGS.items():
            config['is_default'] = False
        
        # Set new default
        MODEL_CONFIGS[model_id]['is_default'] = True
        logger.info(f"Set default model: {model_id}")
        
        return jsonify({"model": MODEL_CONFIGS[model_id]}), 200
    except Exception as e:
        logger.error(f"Error setting default model: {e}", exc_info=True)
        return jsonify({"error": "Failed to set default model"}), 500

@app.route('/api/tframex/models/test', methods=['POST'])
def test_model():
    """Test a model configuration by making a simple API call"""
    logger.info("Request received to test model")
    try:
        data = request.json
        required_fields = ['provider', 'model_name', 'api_key', 'base_url']
        
        for field in required_fields:
            if field not in data:
                return jsonify({"error": f"Missing required field: {field}"}), 400
        
        # Try to create an LLM instance and make a simple test call
        from tframex import OpenAIChatLLM
        try:
            test_llm = OpenAIChatLLM(
                model_name=data['model_name'],
                api_base_url=data['base_url'],
                api_key=data['api_key'],
                parse_text_tool_calls=True
            )
            
            # Make a simple test call
            async def test_call():
                from tframex import Message
                response = await test_llm.chat_completion(
                    messages=[Message(role="user", content="Say 'test successful' in 3 words or less")],
                    stream=False,
                    max_tokens=10
                )
                return response.content if hasattr(response, 'content') else str(response)
            
            result = asyncio.run(test_call())
            
            return jsonify({
                "success": True,
                "message": "Model configuration is valid",
                "response": result
            }), 200
            
        except Exception as e:
            logger.error(f"Model test failed: {e}")
            return jsonify({
                "success": False,
                "error": f"Model test failed: {str(e)}"
            }), 400
            
    except Exception as e:
        logger.error(f"Error testing model: {e}", exc_info=True)
        return jsonify({"error": "Failed to test model"}), 500

@app.route('/api/tframex/register_code', methods=['POST'])
def handle_register_tframex_code():
    data = request.get_json()
    python_code = data.get("python_code")

    if not python_code:
        return jsonify({"error": "Missing 'python_code' in request"}), 400

    logger.info(f"Attempting to register new TFrameX component from user code (length: {len(python_code)}).")

    # Code is registered on the global app instance
    result = register_code_dynamically(python_code, app_instance_to_modify=global_tframex_app)

    if result["success"]:
        return jsonify({"success": True, "message": result["message"]}), 200
    else:
        return jsonify({"success": False, "error": result["message"]}), 500


@app.route('/api/tframex/flow/execute', methods=['POST'])
def handle_execute_tframex_flow():
    run_id = f"sflw_{int(time.time())}_{os.urandom(3).hex()}"
    logger.info(f"--- API Call: /api/tframex/flow/execute (Run ID: {run_id}) ---")

    data = request.get_json()
    visual_nodes = data.get('nodes')
    visual_edges = data.get('edges')
    initial_input_content = data.get("initial_input", "Default starting message for the visual flow.")
    global_flow_template_vars = data.get("global_flow_template_vars", {})

    if not visual_nodes:
        logger.warning(f"Run ID {run_id}: No 'nodes' provided in flow execution request.")
        return jsonify({"output": f"Run ID {run_id}: Error - No visual nodes provided.", "error": "Missing 'nodes' in flow definition"}), 400

    execution_log = [f"--- TFrameX Visual Flow Execution Start (Run ID: {run_id}) ---"]

    # --- Create a temporary TFrameXApp instance for this specific run ---
    # v1.1.0: Include MCP configuration if available
    temp_run_app = TFrameXApp(
        default_llm=global_tframex_app.default_llm,
        mcp_config_file=None  # Don't reload MCP for temp instances
    )
    execution_log.append(f"  Created temporary TFrameXApp for run_id: {run_id}")

    # Re-register all globally known tools onto the temporary app instance
    # This ensures tools added dynamically via UI are available for this run
    if global_tframex_app._tools:
        execution_log.append(f"  Registering {len(global_tframex_app._tools)} global tools onto temporary app...")
        for tool_name, tool_obj in global_tframex_app._tools.items():
            try:
                # Re-register by calling the .tool() decorator method on the temp_run_app instance
                # Provide the JSON schema dictionary for parameters_schema,
                # as tool_obj.parameters (the Pydantic model class) seems to cause issues with '.get()'
                # In v1.1.0, parameters is a Pydantic model, use model_dump
                params_data_dict = tool_obj.parameters.model_dump(exclude_none=True) if tool_obj.parameters else None
                temp_run_app.tool(
                    name=tool_name,
                    description=tool_obj.description,
                    parameters_schema=params_data_dict # Pass the data dictionary
                )(tool_obj.func) # Call the returned decorator with the actual tool function
                execution_log.append(f"    - Tool '{tool_name}' registered on temporary app.")
            except Exception as e_tool_reg:
                error_msg = f"    - Failed to register tool '{tool_name}' on temporary app: {e_tool_reg}"
                logger.error(error_msg)
                execution_log.append(error_msg)
    else:
        execution_log.append("  No global tools to register on temporary app.")
    # --- End temporary app setup ---

    # 1. Translate visual graph to tframex.Flow, using the temporary app for registrations
    constructed_tframex_flow, translation_log_messages, _ = translate_visual_to_tframex_flow(
        flow_id=run_id,
        visual_nodes=visual_nodes,
        visual_edges=visual_edges,
        global_app_instance=global_tframex_app, # Source of base agent definitions
        current_run_app_instance=temp_run_app    # Target for this run's specific agent configs
    )
    execution_log.extend(translation_log_messages)

    if not constructed_tframex_flow:
        error_msg = f"Run ID {run_id}: Failed to translate visual graph into an executable TFrameX Flow."
        logger.error(error_msg)
        execution_log.append(f"\nFATAL ERROR: {error_msg}")
        return jsonify({"output": "\n".join(execution_log), "error": error_msg}), 500

    if not constructed_tframex_flow.steps:
        error_msg = f"Run ID {run_id}: Translated TFrameX Flow has no steps. Nothing to execute."
        logger.warning(error_msg)
        execution_log.append(f"\nWARNING: {error_msg}")
        return jsonify({"output": "\n".join(execution_log), "error": "No executable steps in the flow."}), 200

    execution_log.append(f"\nSuccessfully translated to TFrameX Flow: {constructed_tframex_flow.flow_name} with {len(constructed_tframex_flow.steps)} steps.")
    execution_log.append("TFrameX Flow Steps (Effective Names/Types on Temporary App):")
    for step in constructed_tframex_flow.steps:
        execution_log.append(f"  - {str(step)}") # `str(step)` should show agent name or pattern instance


    # 2. Execute the TFrameX Flow using the temporary app
    final_preview_link = None
    execution_id = None
    
    # Track execution in database if flow_id provided
    if data.get('flow_id'):
        execution_id = create_flow_execution(
            flow_id=data['flow_id'],
            input_data={'initial_input': initial_input_content, 'template_vars': global_flow_template_vars}
        )
    
    try:
        # v1.1.0: Use the temporary app for the run context
        async def execute_flow():
            # Register the flow with the temporary app before creating runtime context
            temp_run_app.register_flow(constructed_tframex_flow)
            
            async with temp_run_app.run_context() as rt:
                
                start_message = Message(role="user", content=str(initial_input_content))
                
                execution_log.append(f"\nRunning TFrameX Flow with initial input: '{start_message.content[:100]}...'")
                if global_flow_template_vars:
                     execution_log.append(f"Global Flow Template Variables: {global_flow_template_vars}")
                
                # Run the flow
                final_flow_context = await rt.run_flow(
                    constructed_tframex_flow,
                    start_message,
                    initial_shared_data={"studio_run_id": run_id},
                    flow_template_vars=global_flow_template_vars
                )
                return final_flow_context
        
        final_flow_context = asyncio.run(execute_flow())
        
        execution_log.append(f"\n--- TFrameX Flow Result (Run ID: {run_id}) ---")
        execution_log.append(f"Final Message Role: {final_flow_context.current_message.role}")
        execution_log.append(f"Final Message Content:\n{final_flow_context.current_message.content}")

        if final_flow_context.current_message.tool_calls:
            tool_calls_summary = json.dumps([tc.model_dump(exclude_none=True) for tc in final_flow_context.current_message.tool_calls], indent=2)
            execution_log.append(f"Final Message Tool Calls (if any, unhandled at flow end):\n{tool_calls_summary}")

        if final_flow_context.shared_data:
             shared_data_summary = {k: (str(v)[:200] + '...' if len(str(v)) > 200 else str(v)) for k,v in final_flow_context.shared_data.items()}
             execution_log.append(f"Final Flow Shared Data:\n{json.dumps(shared_data_summary, indent=2)}")

        if "studio_preview_url" in final_flow_context.shared_data:
            final_preview_link = final_flow_context.shared_data["studio_preview_url"]
            execution_log.append(f"\n--- Preview Link Detected ---")
            execution_log.append(f"PREVIEW_LINK::{final_preview_link}")
            logger.info(f"Run ID {run_id}: Preview link found in shared_data: {final_preview_link}")
        
        # Update execution status in database
        if execution_id:
            update_flow_execution(
                execution_id,
                status='completed',
                output_data={
                    'final_message': final_flow_context.current_message.content,
                    'shared_data': final_flow_context.shared_data
                }
            )

    except Exception as e:
        error_msg = f"Run ID {run_id}: Error during TFrameX flow execution: {e}"
        logger.error(error_msg, exc_info=True)
        execution_log.append(f"\nEXECUTION ERROR: {str(e)}")
        
        # Update execution status in database
        if execution_id:
            update_flow_execution(
                execution_id,
                status='failed',
                error_message=str(e)
            )
        
        # Include the full execution log for debugging
        return jsonify({"output": "\n".join(execution_log), "error": f"Flow execution runtime error: {e}"}), 500

    execution_log.append(f"\n--- TFrameX Visual Flow Execution End (Run ID: {run_id}) ---")
    logger.info(f"Run ID {run_id}: Flow execution finished.")
    # The temp_run_app and its registered components will go out of scope and be garbage collected.
    return jsonify({"output": "\n".join(execution_log)})


# Chatbot for building flows (using two-agent architecture)
@app.route('/api/tframex/chatbot_flow_builder', methods=['POST'])
def handle_tframex_chatbot_flow_builder():
    data = request.get_json()
    user_message = data.get('message')
    current_nodes_json = data.get('nodes', [])
    current_edges_json = data.get('edges', [])

    if not user_message:
        return jsonify({"reply": "Error: No message provided to chatbot.", "flow_update": None}), 400

    logger.info(f"Chatbot flow builder request: '{user_message[:100]}...'")

    # 1. Prepare context for both agents
    available_components_data = discover_tframex_components(app_instance=global_tframex_app)

    ac_context_parts = ["Available TFrameX Components:"]
    for cat in ["agents", "patterns", "tools"]:
        ac_context_parts.append(f"\n{cat.upper()}:")
        for comp in available_components_data.get(cat, []):
            desc = comp.get('description', 'No description.')[:100]
            param_info = ""
            if cat == "patterns":
                param_info = f"(Params: {list(comp.get('constructor_params_schema', {}).keys())})"
            elif cat == "tools":
                param_info = f"(Params: {list(comp.get('parameters_schema', {}).get('properties', {}).keys())})"
            ac_context_parts.append(f"  - ID: {comp['id']}, Name: {comp['name']} {param_info}. Desc: {desc}...")
    available_components_context_str = "\n".join(ac_context_parts)

    current_flow_state_context_str = (
        f"Current Visual Flow State (Nodes: {len(current_nodes_json)}, Edges: {len(current_edges_json)}):\n"
        f"Nodes: {json.dumps(current_nodes_json, indent=2)}\n"
        f"Edges: {json.dumps(current_edges_json, indent=2)}"
    )

    # Check if both agents are registered
    if "ConversationalAssistant" not in global_tframex_app._agents:
        logger.error("Critical: ConversationalAssistant agent is not registered on global app.")
        return jsonify({"reply": "Error: Conversational assistant is not configured.", "flow_update": None}), 500
    
    if "FlowBuilderAgent" not in global_tframex_app._agents:
        logger.error("Critical: FlowBuilderAgent is not registered on global app.")
        return jsonify({"reply": "Error: Flow builder agent is not configured.", "flow_update": None}), 500

    template_vars = {
        "available_components_context": available_components_context_str,
        "current_flow_state_context": current_flow_state_context_str
    }

    try:
        # Two-agent architecture: Assistant -> FlowBuilder
        async def run_chatbot():
            async with global_tframex_app.run_context() as rt:
                return await execute_chatbot_logic(rt, user_message, template_vars)
        
        result_data, status_code = asyncio.run(run_chatbot())
        return jsonify(result_data), status_code
        
    except Exception as e:
        logger.error(f"Error in two-agent chatbot flow builder: {e}", exc_info=True)
        # Always return a valid JSON response structure
        return jsonify({
            "reply": f"Error processing your request: {str(e)}",
            "flow_update": None
        }), 200  # Use 200 to avoid triggering error handlers on frontend

async def execute_chatbot_logic(rt, user_message, template_vars):
    # Step 1: ConversationalAssistant handles user message
    assistant_input = Message(role="user", content=user_message)
    assistant_response = await rt.call_agent(
        "ConversationalAssistant",
        assistant_input,
        template_vars=template_vars
    )
    
    # Ensure we have a valid response
    if not assistant_response or not assistant_response.content:
        logger.error("ConversationalAssistant returned empty response")
        return {
            "reply": "Sorry, I couldn't process your request. The assistant didn't respond.",
            "flow_update": None
        }, 200
    
    assistant_reply = assistant_response.content.strip()
    logger.info(f"ConversationalAssistant response: {assistant_reply[:200]}...")

    # Step 2: Check if assistant wants to modify the flow
    if "FLOW_INSTRUCTION:" in assistant_reply:
        # Extract the flow instruction
        instruction_part = assistant_reply.split("FLOW_INSTRUCTION:")[-1].strip()
        
        # Remove the flow instruction from the user-facing reply
        user_reply = assistant_reply.split("FLOW_INSTRUCTION:")[0].strip()
        
        logger.info(f"Flow instruction detected: {instruction_part[:100]}...")
        
        # Step 3: FlowBuilderAgent generates the flow JSON
        flow_template_vars = {
            **template_vars,
            "flow_instruction": instruction_part
        }
        
        flow_builder_input = Message(role="user", content="Generate ReactFlow JSON based on the instruction.")
        flow_builder_response = await rt.call_agent(
            "FlowBuilderAgent",
            flow_builder_input,
            template_vars=flow_template_vars
        )
        
        flow_json_content = flow_builder_response.content.strip()
        logger.info(f"FlowBuilderAgent response: {flow_json_content[:200]}...")
        
        # Step 4: Parse and validate the JSON
        flow_update_json = None
        try:
            # Handle markdown-wrapped JSON
            if flow_json_content.startswith("```json"):
                # Extract JSON from markdown code block
                start_idx = flow_json_content.find("```json") + 7
                end_idx = flow_json_content.find("```", start_idx)
                if end_idx != -1:
                    flow_json_content = flow_json_content[start_idx:end_idx].strip()
            elif flow_json_content.startswith("```"):
                # Extract JSON from generic code block
                start_idx = flow_json_content.find("```") + 3
                end_idx = flow_json_content.find("```", start_idx)
                if end_idx != -1:
                    flow_json_content = flow_json_content[start_idx:end_idx].strip()
            
            flow_update_json = json.loads(flow_json_content)
            
            if (isinstance(flow_update_json, dict) and
                "nodes" in flow_update_json and isinstance(flow_update_json.get("nodes"), list) and
                "edges" in flow_update_json and isinstance(flow_update_json.get("edges"), list)):
                
                logger.info("Successfully generated valid ReactFlow JSON structure.")
                return {
                    "reply": user_reply or "I've updated the flow based on your request. Please review the canvas.",
                    "flow_update": flow_update_json
                }, 200
            else:
                logger.warning(f"Flow builder returned JSON with invalid structure: {flow_json_content[:500]}...")
                return {
                    "reply": user_reply + "\n\nI tried to update the flow, but the structure wasn't quite right. Could you try rephrasing your request?",
                    "flow_update": None
                }, 200
                
        except json.JSONDecodeError as e:
            logger.error(f"Flow builder response was not valid JSON: {e}. Raw response: {flow_json_content[:1000]}...")
            return {
                "reply": user_reply + "\n\nI had trouble generating the flow update. Could you try rephrasing your request?",
                "flow_update": None
            }, 200
    else:
        # No flow modification requested, just return the conversational response
        return {
            "reply": assistant_reply,
            "flow_update": None
        }, 200


# Preview route for files generated by TFrameX
@app.route('/api/tframex/preview/<run_id>/<path:filepath>')
def serve_generated_tframex_studio_file(run_id, filepath):
    logger.info(f"Request for TFrameX Studio preview: run_id={run_id}, filepath={filepath}")
    if '..' in run_id or '..' in filepath:
        logger.warning(f"Path traversal attempt denied: {run_id}/{filepath}")
        return "Invalid path", 403

    directory_to_serve_from = os.path.abspath(os.path.join(TFRAMEX_GENERATED_FILES_DIR, run_id))

    if not directory_to_serve_from.startswith(os.path.abspath(TFRAMEX_GENERATED_FILES_DIR)):
         logger.error(f"Attempt to access directory outside allowed generated folder: {directory_to_serve_from}")
         return "Access denied", 403

    if not os.path.isdir(directory_to_serve_from):
        logger.warning(f"Preview directory not found for run_id '{run_id}': {directory_to_serve_from}")
        return "Run ID not found or no files generated.", 404

    try:
        logger.debug(f"Attempting to send file: {filepath} from directory: {directory_to_serve_from}")
        return send_from_directory(directory_to_serve_from, filepath)
    except FileNotFoundError:
        logger.warning(f"File not found in preview request: {filepath} in {directory_to_serve_from}")
        return "File not found.", 404
    except Exception as e:
         logger.error(f"Error serving generated file '{filepath}' for run_id '{run_id}': {e}", exc_info=True)
         return "Error serving file.", 500


def create_app():
    """Application factory pattern"""
    return app

if __name__ == '__main__':
    # Configuration from environment
    host = os.getenv('FLASK_RUN_HOST', '0.0.0.0')
    port = int(os.getenv('FLASK_RUN_PORT', 5000))
    debug_mode = os.getenv('FLASK_ENV', 'development').lower() == 'development'
    
    # Log startup information
    logger.info(f"Starting Agent-Builder Backend")
    logger.info(f"Host: {host}:{port}")
    logger.info(f"Debug: {debug_mode}")
    logger.info(f"TFrameX Version: 1.1.0")
    
    # Check if frontend is built
    frontend_dist = os.path.join(os.path.dirname(__file__), '../frontend/dist/index.html')
    if os.path.exists(frontend_dist):
        logger.info("Frontend build detected - serving static files")
    else:
        logger.info("No frontend build found - API only mode")
    
    # Run the app
    app.run(
        host=host,
        port=port,
        debug=debug_mode,
        use_reloader=False  # Disable reloader in async context
    )